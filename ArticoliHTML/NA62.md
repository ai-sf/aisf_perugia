---
layout: page
permalink: /ArticoliHTML/na62/
---
<html>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<center>
 <h2>L'esperimento NA62</h2>
<h7 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-7"><em>A cura di Francesco Brizioli, 13 Aprile 2017</em></h7><br>
<h4>Alla ricerca di indizi per comprendere la natura intima delle cose&nbsp;</h4></center>

<figure>  
<center>
 <img src="/na62/image1.png" alt="centered image" style="max-width:100%"
 height="auto" width="600" class="responsive">
</center>
<center>
 <figcaption>  <b><em>L'esperimento NA62 al Cern di Ginevra.</em></b> </figcaption>
</center>
</figure>
<br>
Nell’evoluzione del sapere scientifico vi sono momenti considerati più prosperosi, cioè lassi di tempo relativamente brevi in cui si fanno passi da giganti, e periodi, anche lunghi, in cui invece, per diversi motivi sembra che la situazione sia in stallo e non si sa in quale direzione dover guardare per sperare di trovare una qualche illuminazione che indichi una possibile strada per andare avanti.<br>

Ciò che determina nella maggior parte dei casi la transizione da periodo di progresso a periodo di stallo, è il convincimento, anche delle menti più brillanti, di essere giunti al capolinea, di non poter migliorare ulteriormente lo stato delle cose.<br><br>

Ad esempio, da quando Aristotele ha formulato la sua concezione sulla struttura dell’universo, che oggi sappiamo essere profondamente sbagliata, ma in quel momento era ciò che serviva all’uomo per interpretare ciò che osservava e per rassicurarsi sul perché della propria esistenza in questo mondo, sono serviti secoli per ricominciare a fare ricerca, capendo che forse quanto già faceva parte della cultura non era del tutto soddisfacente, non essendo in grado di rispondere in maniera convincente a dubbi che emergevano dalle osservazioni della natura. E quindi il lungo periodo di stallo ha iniziato a portare qualche frutto, gettando le basi per la Rivoluzione Copernicana, che ha dato il via ad un periodo di grandi progressi: si pensi ad esempio al lavoro di Galilei e Newton, i quali hanno ribaltato il modo di osservare e descrivere il mondo circostante.<br><br>

In altre situazioni la società umana è stata più fortunata, poiché ci è voluto meno tempo per iniziare a far fruttare momenti di apparente stallo, mettendo in dubbio ciò che già si conosceva per migliorare il livello di indagine andando sempre più nel dettaglio della natura. Si pensi in tal senso alla sintesi che Maxwell opera durante la seconda metà dell’800 nell’ambito della fisica classica, in particolare nel campo dell’elettromagnetismo, scrivendo le sue quattro equazioni: sembrava quello il momento in cui la fisica fosse davvero arrivata al capolinea, perché si era in grado di modellizzare mediante il rigoroso linguaggio della matematica tutti i fenomeni macroscopici che si potevano osservare.<br><br>

Ci si sarebbe allora potuti fermare con il porsi domande, ed invece, senza dover aspettare secoli (come fra Aristotele e Copernico), ma soltanto qualche anno, ci si è iniziati a chiedere come le teorie note potessero essere ampliate per spiegare anche fenomeni non relativi alle scale della vita di tutti i giorni, ma in limiti particolari, come i corpi che si muovono a grandissime velocità (ciò che poi è diventata la fisica relativistica) e il mondo microscopico (che adesso descriviamo tramite la meccanica quantistica), che sembravano dissentire dalle conoscenze attuali.<br><br>


<figure>  
<center>
 <img src="/na62/image2.png" style="max-width:100%"
 height="auto" width="300" class="responsive">
</center>
<center>
<figcaption>  <b><em>Busto di Aristotele conservato a Palazzo Altemps, Roma</em></b> </figcaption>
</center>

</figure>

<br>
Quello che adesso ci si potrebbe chiedere è: che tipo di momento sta attraversando la conoscenza della natura da parte del genere umano? Difficile rispondere a questo interrogativo, almeno per quanto riguarda la fisica delle interazioni fondamentali, anche detta fisica delle particelle elementari o delle alte energie. È questa la parte della scienza che attualmente cerca di modellizzare tramite leggi matematiche le interazioni più profonde che avvengono in natura, sia su scala macroscopica che su scala microscopica, sia al giorno d’oggi che pochissimi istanti dopo l’origine del nostro universo, il Big Bang.<br><br>

La difficoltà di questo tipo di ricerca risiede nel fatto che il mondo come noi oggi lo vediamo, evidentemente non è lo stesso rispetto a qualche istante dopo l’alba dell’universo, per cui se ci limitassimo ad osservarlo nelle sue condizioni stabili di adesso, sicuramente non avremmo a disposizione gli stessi fenomeni che avvenivano in situazioni più esotiche, in momenti come quelli immediatamente dopo il Big Bang. È necessario quindi, se si vuole fare questo tipo di ricerca, realizzare un laboratorio in cui tali condizioni si riescano a riprodurre, e quindi, proprio come si farebbe con una macchina del tempo, si possano andare ad osservare gli stessi fenomeni che avvenivano in passato, e che poi hanno portato alla formazione degli oggetti che oggi ci sono più familiari (galassie, sistemi solari, buchi neri …).<br><br>

Ciò significa, evidentemente, spingersi a densità di energie molto molto elevate (si pensi a quanta energia era concentrata in uno spazio piuttosto piccolo nel momento del Big Bang), da cui l’appellativo fisica delle alte energie, dove si formano ed interagiscono fra loro degli oggetti che sono i costituenti fondamentali del nostro universo (o, quantomeno, lo sono stati in una certa epoca cosmologica), quelle che oggi chiamiamo particelle elementari.<br><br>

Per ora abbiamo utilizzato essenzialmente due tipi di laboratori dove tali condizioni sono ricreate: uno messoci a disposizione direttamente dalla natura, cioè i raggi cosmici, che vengono studiati sia da terra sia andando nello spazio, ed uno che invece è forse la più grande manifestazione del sapere ingegneristico di cui disponiamo, gli acceleratori, cioè delle macchine in grado di portare particelle che ancora oggi compongono la materia ordinaria che ci circonda (elettroni, protoni, ed eventualmente le rispettive antiparticelle), a velocità prossime a quelle della luce.


<figure>  
<center>
 <img src="/na62/image4.png" style="max-width:100%"
 height="auto" width="400" class="responsive">
</center>
<center>
<figcaption>  <b><em>Schema delle particelle fondamentali descritte dal Modello Standard</em></b> </figcaption>
</center>

</figure>


<br>
In questo modo si hanno a disposizione delle enormi quantità di energia concentrate in piccolissime porzioni di spazio, con cui si possono riprodurre le condizioni esotiche volute.
<br><br>
Tale filone di ricerca, che non ha nemmeno un secolo di vita, ci ha portato ad una conoscenza molto approfondita di quali siano i costituenti fondamentali del nostro universo, e dei modi in cui essi interagiscono, permettendoci di raccogliere molti dati sperimentali e di elaborare una teoria che sia in grado di predire e spiegare tali risultati. La teoria che racchiude tutte le nostre conoscenze in questo campo di chiama Modello Standard delle interazioni fondamentali.<br><br>

Da questo punto di vista l’ultimo secolo può essere considerato un periodo molto prolifico per il progresso scientifico e tecnologico, il cui culmine si è probabilmente raggiunto nel 2012 con l’annuncio dell’osservazione di una particella che era alla base della nostra teoria, il cosiddetto Bosone di Higgs.<br><br>

Ma adesso, dopo il grande successo, a che punto ci troviamo? Questa scoperta rappresenta un punto di arrivo o un punto di partenza?<br>
Imparando dal passato, per la comunità scientifica esso vorrebbe essere solo un punto di partenza. Il problema è capire verso quale direzione puntare. Infatti da un lato il Modello Standard lascia aperte tante domande, come ad esempio, che cosa sia l’energia e la materia oscura, che sembrano costituire circa il 95% dell’universo, o perché in questo momento nell’universo vi sia una totale prevalenza della materia sull’antimateria, e numerose altre evidenze per cui la teoria non riesce a dare una spiegazione soddisfacente.
<br><br>
Questo fatto di per se non rappresenterebbe un problema, almeno nell’ottica della visione della scienza dell’epistemologo Karl Popper, il quale sosteneva che la scienza deve procedere per falsificazioni, ed una teoria è scientifica quanto più è falsificabile, perché mediante il processo di falsificazione si riesce a correggere ed ampliare la teoria sempre di più, così da renderla sempre più adatta a descrivere i fenomeni della natura: avere dei buchi nella teoria, quindi delle possibili falsificazioni non è dunque altro che un aspetto positivo per poterla migliorare.<br><br>

Ma, dall’altro lato, qualsiasi altro modello, che per il momento sia venuto in mente a chi fa ricerca in questo ambito, che superi il Modello Standard e sappia dare risposta a qualcuna delle domande ancora aperte non trova alcun riscontro sperimentale. L’esempio più calzante è quello della teoria della Supersimmetria (SUSY), la quale prevedeva di estendere il Modello Standard “raddoppiandolo”, cioè aggiungendo ad ogni particella standard un suo partner super-simmetrico. Questa teoria sarebbe stata in grado, tra l’altro, di dare una possibile interpretazione della materia oscura. Tuttavia ad oggi, le misure che continuano ad essere fatte nei laboratori di tutto il mondo (spazio compreso) non stanno trovando alcuna evidenza che dia riscontro a queste teorie, ma soltanto conferme al Modello Standard.<br><br>

Siamo allora forse in una fase di stallo nel comprendere i misteri più profondi sull’essenza del nostro universo, non tanto perché soddisfatti di ciò che già abbiamo, ma perché non sappiamo dove guardare, perché la natura non ci sta offrendo degli indizi validi per approfondire la nostra conoscenza e rispondere a domande ora ignote.
Uno dei modi per cercare degli indizi che permettano di falsificare il Modello Standard è quello di osservare degli eventi che, almeno per quanto ne sappiamo ora, avvengano molto raramente e per cui la conoscenza teorica (che vorremmo smentire, per trovare un indizio di quella che chiamiamo Nuova Fisica) sia abbastanza buona.<br>



<figure>  
<center>
 <img src="/na62/Forces.png" style="max-width:100%"
 height="auto" width="600" class="responsive">
</center>
<center>
<figcaption>  <b><em>Confronto tra l'unificazione delle forze nel Modello Standard e la teoria della Supersimmetria</em></b> </figcaption>
</center>

</figure>
<br>
La rarità è essenziale perché, facendo una metafora, è intuitivo come sia più facile trovare una pallina nera (ciò che non si conosce, cioè eventi non previsti dal Modello Standard) in mezzo a dieci palline bianche (ciò che è previsto dal nostro attuale modello), rispetto al trovare la stessa pallina nera in mezzo a diecimila palline bianche. In altre parole è più facile che effetti non standard si manifestino quando non sono troppo mascherati da effetti standard.

La buona conoscenza di ciò che ci aspettiamo (cioè la previsione che il Modello Standard fa sul nostro fenomeno) è altrettanto importante poiché il confronto fra due risultati è tanto più efficace, e quindi potenzialmente utile a determinare una discrepanza fra misura e teoria, quindi una falsificazione della teoria stessa, quanto più le incertezze sui risultati siano piccole.
Naturalmente con questo tipo di ricerca non si sa verso dove si sta andando, ma semplicemente si tenta di mettere alla prova la conoscenza di cui adesso disponiamo, sperando di trovare qualche indizio di novità che permetta di ampliarla.
Con questa idea sono nati numerosi esperimenti che analizzano processi profondamente legati alla teoria delle interazioni, molto rari, e di cui la teoria è in grado di fare predizioni molto accurate.

Uno dei tanti processi attualmente in fase di studio è il decadimento di una particella chiamata kaone carico in altre tre particelle, un pione carico ed una coppia neutrino-antineutrino:   $$K_+ \rightarrow  \pi+ \nu + \bar{\nu} = (0.84 \pm 0.10) \cdot 10^{−10}$$
Si tratta di un processo molto raro in quanto è previsto che ne avvenga uno ogni 10 miliardi di decadimenti del kaone, e la cui previsione sulla frazione di decadimento (branching ratio, cioè il numero di decadimenti di quel tipo che avvengono rispetto al numero di decadimenti totali della particella) ha un’incertezza di circa il 10%:


Un modo per poter quindi mettere alla prova il Modello Standard è quindi quello di identificare questi tipi di eventi, dovendoli distinguere da altri decadimenti, molto simili dal punto di vista della segnatura sperimentale (cioè i segnali che le particelle rilasciano nei rivelatori) ma molto più frequenti, ed effettuare una misura della frazione di decadimento con una buona precisione così da confrontarla con la previsione teorica ed eventualmente evidenziare effetti di nuova fisica.
Questo è ciò che sta tentando di fare l’esperimento NA62, installato al CERN lungo una linea di fascio di protoni estratta dall’acceleratore SPS. L’istallazione dell’esperimento è terminata nel 2016, quando si è iniziato a raccogliere dati utili alle analisi di fisica. Successivamente si sono raccolti dati nel 2017, e da poco (lo scorso 9 aprile) è iniziato un nuovo anno di presa dati.

Per poter raggiungere il suo scopo, NA62 ha bisogno di rivelatori di particelle che permettano di identificare il decadimento si segnale e contemporaneamente di rigettare gli altri decadimenti (detti “di fondo”, che hanno caratteristiche simili).

Il decadimento di segnale ha una segnatura sperimentale molto semplice: si ha un’unica particella carica, un pione, che quindi rilascerà la sua energia nei vari rivelatori (in diversi modi, in base a qual è il processo fisico che viene sfruttato dal rivelatore per osservare la particella), e due neutrini, i quali hanno probabilità praticamente nulla di interagire con i rivelatori di NA62, per cui l’unica “segnatura” che essi hanno è energia mancante fra il kaone prima del decadimento e il pione prodotto dal decadimento, che corrisponde all’energia presa dai due neutrini, che quindi viene persa dai rivelatori.

Tutti gli altri canali di decadimento avranno delle segnature diverse, in base alle particelle che compongono lo stato finale. I due canali che costituiscono il fondo principale per il segnale sono i seguenti:

$$K^+ \rightarrow  \pi+ \pi_0 (detto K2pi) ;$$
$$K^+ \rightarrow   \mu + \nu  (detto Kmu2);$$

entrambi hanno probabilità di avvenire oltre un miliardo di volte superiore rispetto a quella del decadimento di segnale. Questi due decadimenti hanno in teoria una segnatura sperimentale diversa dal decadimento cercato: infatti nel K2pi oltre al pione carico vi è il pione neutro, che decade quasi sempre in due fotoni, i quali sono facilmente osservabili dai rivelatori di NA62; il Kmu2 ha come particella carica un muone anziché un pione, e per fortuna queste due particelle cariche interagiscono in maniera molto diversa (i muoni riescono a penetrare la materia molto più profondamente rispetto ai pioni).


<figure>  
<center>
 <img src="/na62/image3.png" style="max-width:100%"
 height="auto" width="600" class="responsive">
</center>
<center>
<figcaption>  <b><em> Il logo di NA62 è affiancato dal diagramma di Feynman del decadimento studiato, simile ad un pinguino stilizzato.</em></b> </figcaption>
</center>

</figure>
<br><br>
Il problema è che, essendo molto più frequenti rispetto al decadimento si segnale, è sufficiente sbagliare anche poche volte nell’identificazione del decadimento per ottenere un numero di eventi di fondo che sovrasta gli eventi di segnale. Se ad esempio i due fotoni provenienti dal pione neutro del decadimento K2pi vengono per un qualche motivo persi (ad esempio perché finiscono in una regione morta, cioè dei pezzi dei rivelatori che non sono in grado di raccogliere i segnali), allora esso può essere confuso con il decadimento di segnale. E, date le probabilità relative dei decadimenti, è sufficiente sbagliarsi anche soltanto una volta ogni miliardo nella reiezione dei canali di fondo per avere una presenza di essi maggiore di quella degli eventi di segnale (che corrisponderebbe ad effettuare la misura con errore superiore al 100\%). È quindi necessario un livello di accuratezza estremamente elevato.<br><br>

Quello di cui ha dunque bisogno NA62 è un insieme di rivelatori che siano il più possibile ermetici, cioè che siano in grado di rivelare tutte le particelle prodotte nei decadimenti (ad eccezione dei neutrini), e che possano identificare sia i fotoni che la natura delle particelle cariche presenti (pioni, muoni, elettroni).<br><br>

Per poter riuscire nell’impresa si fa inoltre utilizzo della cosiddetta analisi cinematica, cioè l’applicazione di leggi di conservazione (energia ed impulso) fra stato iniziale e stato finale, che consente di migliorare ulteriormente la capacità di identificazione del segnale e di reiezione del fondo. Per poter effettuare questa analisi è necessario che i rivelatori di NA62 siano in grado di misurare con precisione energia, impulso e direzione di moto delle particelle sia prima (kaone) sia dopo il decadimento.<br>

<section>
<center><h3>  Approfondimento </h3></center>
</section>
Per ulteriori dettagli sull’esperimento NA62 si rimanda all’articolo scientifico
<a href="http://iopscience.iop.org/article/10.1088/1748-0221/12/05/P05025"> “E. Cortina Gil et al 2017 JINST 12 P05025” </a>, nonché a tutta la documentazione presente nella pagina web dell’esperimento,<a href="https://na62.web.cern.ch/na62/."> https://na62.web.cern.ch/na62/.</a> <br><br>

Gli unici dati che per ora sono stati completamente analizzati sono quelli del 2016, da cui è già emerso un risultato molto importante: è stato verificato che la tecnica sperimentale utilizzata da NA62 funziona, ed è stato osservato un evento candidato ad essere proprio il decadimento ultra-raro \(K^+ \rightarrow   \pi + \nu + \bar{\nu} \).<br><br>

La Collaborazione NA62, di cui una parte rilevante è costituita da gruppi italiani, fra cui il gruppo dell’Università e dell’INFN (Istituto Nazionale di Fisica Nucleare) di Perugia, ha annunciato tale risultato lo scorso marzo, ed è confidente che con i dati del 2017 e del 2018 si possa ottenere un significativo numero di eventi, così da poter effettuare una misura della frazione dei decadimento abbastanza precisa da essere confrontata con la teoria per andare a caccia di qualche indizio sul dove guardare per scrutare la natura ancora più a fondo, e, magari, andare verso la comprensione di aspetti che per ora risultano del tutto ignoti.<br><br>

Un buon punto di partenza, che forse ci indicherà quale sia la strada giusta per mirare all’arrivo, se un arrivo effettivamente esiste, oppure semplicemente un nuovo punto di partenza!
